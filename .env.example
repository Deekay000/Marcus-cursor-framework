# ============================================================================
# Marcus AI Avatar - Environment Configuration Template
# ============================================================================
# Copy this file to .env and fill in your actual values:
#   cp .env.example .env
#
# DO NOT commit .env to Git (contains secrets)
# ============================================================================

# ============================================================================
# 1. ENVIRONMENT SETTINGS
# ============================================================================
# Runtime environment: development, staging, production
# Controls default behaviors like logging verbosity and hot reload
ENVIRONMENT=development

# Enable debug mode with verbose logging
# Set to true in development, false in staging/production
DEBUG=false

# ============================================================================
# 2. DATABASE SETTINGS (PostgreSQL)
# ============================================================================
# PostgreSQL connection URL (REQUIRED - no default)
# Format: postgresql+asyncpg://user:password@host:port/database
# The +asyncpg driver is required for async SQLAlchemy
DATABASE_URL=postgresql+asyncpg://marcus:marcus_dev_password@localhost:5432/marcus_dev

# Connection pool size (default: 10)
# Higher values support more concurrent database queries
DATABASE_POOL_SIZE=10

# Maximum overflow connections beyond pool size (default: 20)
# Used for handling burst traffic
DATABASE_MAX_OVERFLOW=20

# Echo SQL queries to logs (default: false)
# Enable for debugging SQL, disable in production for performance
DATABASE_ECHO=false

# ============================================================================
# 3. REDIS SETTINGS
# ============================================================================
# Redis connection URL (REQUIRED - no default)
# Format: redis://[[username]:[password]@]host:port/database
REDIS_URL=redis://localhost:6379/0

# Maximum Redis connections (default: 50)
# Higher values support more concurrent cache operations
REDIS_MAX_CONNECTIONS=50

# ============================================================================
# 4. OPENAI SETTINGS
# ============================================================================
# OpenAI API key (REQUIRED - no default)
# Get your key from: https://platform.openai.com/api-keys
# SECURITY: Never commit actual API keys to version control
OPENAI_API_KEY=sk-your-key-here

# OpenAI model to use (default: gpt-4o-mini)
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# gpt-4o-mini offers good balance of quality and cost
OPENAI_MODEL=gpt-4o-mini

# Response temperature (default: 0.7)
# Range: 0.0-2.0
# Lower = more deterministic/focused, Higher = more creative/varied
OPENAI_TEMPERATURE=0.7

# Maximum tokens in response (default: 500)
# Controls maximum response length
# Marcus responses should be concise for real-time interaction
OPENAI_MAX_TOKENS=500

# API request timeout in seconds (default: 30)
# Must accommodate network latency and model response time
OPENAI_TIMEOUT=30

# ============================================================================
# 5. BEHAVIORAL CONFIG SETTINGS
# ============================================================================
# Path to Marcus behavioral configuration YAML
# Contains personality traits, emotional states, response patterns
BEHAVIOR_CONFIG_PATH=src/behavior/behavior_config.yaml

# ============================================================================
# 6. OBSERVABILITY SETTINGS
# ============================================================================
# Logging level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development, INFO or WARNING for production
LOG_LEVEL=INFO

# Log format (default: json)
# Options: json (structured, for log aggregation), text (human-readable)
# Use json in production for ELK/Datadog, text in development
LOG_FORMAT=json

# Log file path (default: None - stdout only)
# Set to file path for persistent logging
# Example: /var/log/marcus/app.log
# Leave empty for stdout only (recommended for containerized deployments)
LOG_FILE=

# ============================================================================
# 7. METRICS SETTINGS
# ============================================================================
# Enable Prometheus metrics endpoint (default: true)
# Exposes /metrics endpoint for monitoring
METRICS_ENABLED=true

# Prometheus metrics port (default: 9090)
# Separate from API port for security
METRICS_PORT=9090

# ============================================================================
# 8. API SETTINGS
# ============================================================================
# API server bind host (default: 0.0.0.0)
# 0.0.0.0 = all interfaces, 127.0.0.1 = localhost only
API_HOST=0.0.0.0

# API server port (default: 8000)
API_PORT=8000

# Enable hot reload (default: true)
# Automatically restarts server on code changes
# Enable in development, disable in production
API_RELOAD=true

# Allowed CORS origins (default: ["http://localhost:3000"])
# Comma-separated list of allowed origins
# Be specific in production - avoid * for security
# Format: comma-separated URLs
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# API request timeout in seconds (default: 30)
# Should accommodate full pipeline: LLM + TTS + FLAME
API_REQUEST_TIMEOUT=30

# ============================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# ============================================================================
#
# DEVELOPMENT (default):
#   ENVIRONMENT=development
#   DEBUG=true
#   LOG_LEVEL=DEBUG
#   LOG_FORMAT=text
#   API_RELOAD=true
#   DATABASE_ECHO=true
#
# STAGING:
#   ENVIRONMENT=staging
#   DEBUG=false
#   LOG_LEVEL=INFO
#   LOG_FORMAT=json
#   API_RELOAD=false
#
# PRODUCTION:
#   ENVIRONMENT=production
#   DEBUG=false
#   LOG_LEVEL=WARNING
#   LOG_FORMAT=json
#   API_RELOAD=false
#   CORS_ORIGINS=https://your-production-domain.com
#
# ============================================================================
